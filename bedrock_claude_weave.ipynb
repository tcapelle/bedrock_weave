{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a26a16-79e4-4635-83f0-b9d39fac8282",
   "metadata": {},
   "source": [
    "# Using Weights & Biases `Weave` with AWS `Bedrock`\n",
    "\n",
    "In this notebook, you will learn to use our newly released tool for LLM practitioners.\n",
    "\n",
    "You can use [Weave](https://wandb.github.io/weave/) to:\n",
    "\n",
    "- Log and debug language model inputs, outputs, and traces\n",
    "- Build rigorous, apples-to-apples evaluations for language model use cases\n",
    "- Organize all the information generated across the LLM workflow, from experimentation and evaluations to production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1835b-7b58-41e3-b427-e6aefb6bfb5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0417fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws sso login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace11bef-d89e-4439-ad1d-00a603fd9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"weave=0.50.15\" boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b81f67-d5eb-4489-a20c-e11337d25e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from utils import mprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ab8c6-191f-4ae0-a11c-d0eac506be72",
   "metadata": {},
   "source": [
    "## Create a Weights & Biases `Weave` project to store your traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e426e5-f60e-4333-8f4a-38ceac4af672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: capecape.\n",
      "View Weave data at https://wandb.ai/capecape/aws-genai/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.weave_client.WeaveClient at 0x12ffb7620>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "weave.init('aws-genai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbfcdf-780a-4b62-a235-1b32ff3b6d9f",
   "metadata": {},
   "source": [
    "Decorate your function call, that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64b3e2a-85ea-4514-8fe4-7d6fed2ff517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "@weave.op # <- just add this üòé\n",
    "def call_model(\n",
    "    model_id: str, \n",
    "    messages: str, \n",
    "    system_message: str,\n",
    "    max_tokens: int=400,\n",
    "    ) -> dict:\n",
    "\n",
    "        \n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        system=[{\"text\":\"system_message\"}], # it needs a list for some reason\n",
    "        messages=messages,\n",
    "        inferenceConfig={\n",
    "            \"maxTokens\": max_tokens\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899140e-11b1-4dba-be2c-6319548e7e89",
   "metadata": {},
   "source": [
    "Let's first try using the amazing `Claude Sonnet 3.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db351094-c5b7-4194-af04-b4ddc85399c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04b-b303-7831-9543-aad716530296\n"
     ]
    }
   ],
   "source": [
    "model_id = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "system_message = \"You are an expert software engineer that knows a lot of programming. You prefer short answers.\"\n",
    "messages = [{\"role\": \"user\", \n",
    "             \"content\": [\n",
    "                 {\"text\": (\n",
    "                         \"In Bash, how do I list all text files in the current directory \"\n",
    "                         \"(excluding subdirectories) that have been modified in the last month?\")\n",
    "                  }\n",
    "                 ]\n",
    "            }\n",
    "            ]\n",
    "\n",
    "outputs = call_model(model_id, messages, system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4916de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
      "                                      'content-length': '1580',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Fri, 18 Oct 2024 15:42:58 GMT',\n",
      "                                      'x-amzn-requestid': 'e3107ee0-c564-41fe-bf8f-7ce97c70d086'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'e3107ee0-c564-41fe-bf8f-7ce97c70d086',\n",
      "                      'RetryAttempts': 0},\n",
      " 'metrics': {'latencyMs': 9079},\n",
      " 'output': {'message': {'content': [{'text': 'To list all text files in the '\n",
      "                                             'current directory (excluding '\n",
      "                                             'subdirectories) that have been '\n",
      "                                             'modified in the last month using '\n",
      "                                             'Bash, you can use the `find` '\n",
      "                                             'command combined with some '\n",
      "                                             \"options. Here's how you can do \"\n",
      "                                             'it:\\n'\n",
      "                                             '\\n'\n",
      "                                             '```bash\\n'\n",
      "                                             'find . -maxdepth 1 -type f -name '\n",
      "                                             '\"*.txt\" -mtime -30\\n'\n",
      "                                             '```\\n'\n",
      "                                             '\\n'\n",
      "                                             \"Let's break down this command:\\n\"\n",
      "                                             '\\n'\n",
      "                                             '1. `find .`: Start searching in '\n",
      "                                             'the current directory.\\n'\n",
      "                                             '\\n'\n",
      "                                             '2. `-maxdepth 1`: Limit the '\n",
      "                                             'search to the current directory '\n",
      "                                             \"only (don't go into \"\n",
      "                                             'subdirectories).\\n'\n",
      "                                             '\\n'\n",
      "                                             '3. `-type f`: Look for files '\n",
      "                                             'only (not directories).\\n'\n",
      "                                             '\\n'\n",
      "                                             '4. `-name \"*.txt\"`: Match files '\n",
      "                                             'with the .txt extension. You can '\n",
      "                                             'modify this pattern if you want '\n",
      "                                             'to include other text file '\n",
      "                                             'extensions.\\n'\n",
      "                                             '\\n'\n",
      "                                             '5. `-mtime -30`: Find files '\n",
      "                                             'modified within the last 30 '\n",
      "                                             'days.\\n'\n",
      "                                             '\\n'\n",
      "                                             'If you want to include other '\n",
      "                                             'text file extensions, you can '\n",
      "                                             'modify the command like this:\\n'\n",
      "                                             '\\n'\n",
      "                                             '```bash\\n'\n",
      "                                             'find . -maxdepth 1 -type f \\\\( '\n",
      "                                             '-name \"*.txt\" -o -name \"*.log\" '\n",
      "                                             '-o -name \"*.md\" \\\\) -mtime -30\\n'\n",
      "                                             '```\\n'\n",
      "                                             '\\n'\n",
      "                                             'This will include .txt, .log, '\n",
      "                                             'and .md files.\\n'\n",
      "                                             '\\n'\n",
      "                                             'If you want a more detailed '\n",
      "                                             'listing, you can pipe the '\n",
      "                                             'results to `ls -l`:\\n'\n",
      "                                             '\\n'\n",
      "                                             '```bash\\n'\n",
      "                                             'find . -maxdepth 1 -type f -name '\n",
      "                                             '\"*.txt\" -mtime -30 -print0 | '\n",
      "                                             'xargs -0 ls -l\\n'\n",
      "                                             '```\\n'\n",
      "                                             '\\n'\n",
      "                                             'This will show you the file '\n",
      "                                             'permissions, owner, size, and '\n",
      "                                             'exact modification date for each '\n",
      "                                             'file.\\n'\n",
      "                                             '\\n'\n",
      "                                             'Remember that `-mtime -30` '\n",
      "                                             'checks for files modified in the '\n",
      "                                             'last 30 days. If you need '\n",
      "                                             'exactly one month (which could '\n",
      "                                             'be 28,'}],\n",
      "                        'role': 'assistant'}},\n",
      " 'stopReason': 'max_tokens',\n",
      " 'usage': {'inputTokens': 40, 'outputTokens': 400, 'totalTokens': 440}}\n"
     ]
    }
   ],
   "source": [
    "pprint(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b187be1",
   "metadata": {},
   "source": [
    "realising this, we can refactor the code to be more concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f700b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def format_prompt(prompt: str) -> list[dict]:\n",
    "    return [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def claude(model_id: str, prompt: str, max_tokens: int=400) -> str:\n",
    "    messages = format_prompt(prompt)\n",
    "    response = call_model(model_id, messages, system_message, max_tokens)\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edd54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04b-de93-7de1-a87b-9b43ffbb50bd\n"
     ]
    }
   ],
   "source": [
    "prompt = (\"Give me a super simple starting code in PyTorch for training of a diffusion model. \" \n",
    "          \"Use a minimal dataset like CIFAR10\")\n",
    "response = claude(model_id, prompt, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343aad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a super simple starting code for training a diffusion model using PyTorch and the CIFAR10 dataset. This example is minimal and doesn't include all the optimizations and complexities of a full-fledged diffusion model, but it should give you a good starting point:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "from torchvision import datasets, transforms\n",
       "from torch.utils.data import DataLoader\n",
       "\n",
       "# Hyperparameters\n",
       "batch_size = 64\n",
       "num_epochs = 100\n",
       "learning_rate = 1e-4\n",
       "num_timesteps = 1000\n",
       "beta_start = 0.0001\n",
       "beta_end = 0.02\n",
       "\n",
       "# Device configuration\n",
       "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
       "\n",
       "# Load CIFAR10 dataset\n",
       "transform = transforms.Compose([\n",
       "    transforms.ToTensor(),\n",
       "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
       "])\n",
       "\n",
       "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
       "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
       "\n",
       "# Simple U-Net model\n",
       "class SimpleUNet(nn.Module):\n",
       "    def __init__(self):\n",
       "        super(SimpleUNet, self).__init__()\n",
       "        self.down1 = nn.Conv2d(3, 64, 3, padding=1)\n",
       "        self.down2 = nn.Conv2d(64, 128, 3, padding=1)\n",
       "        self.up1 = nn.ConvTranspose2d(128, 64, 3, padding=1)\n",
       "        self.up2 = nn.ConvTranspose2d(64, 3, 3, padding=1)\n",
       "        self.act = nn.ReLU()\n",
       "\n",
       "    def forward(self, x, t):\n",
       "        t = t.unsqueeze(-1).unsqueeze(-1)\n",
       "        x1 = self.act(self.down1(x + t))\n",
       "        x2 = self.act(self.down2(x1 + t))\n",
       "        x = self.act(self.up1(x2 + t))\n",
       "        x = self.up2(x + x1 + t)\n",
       "        return x\n",
       "\n",
       "# Diffusion model\n",
       "class DiffusionModel:\n",
       "    def __init__(self):\n",
       "        self.model = SimpleUNet().to(device)\n",
       "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
       "        self.mse = nn.MSELoss()\n",
       "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
       "        self.alphas = 1 - self.betas\n",
       "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
       "\n",
       "    def train_step(self, x):\n",
       "        t = torch.randint(0, num_timesteps, (x.shape[0],)).to(device)\n",
       "        noise = torch.randn_like(x)\n",
       "        x_noisy = self.add_noise(x, t, noise)\n",
       "        predicted_noise = self.model(x_noisy, t.float() / num_timesteps)\n",
       "        loss = self.mse(noise, predicted_noise)\n",
       "        \n",
       "        self.optimizer.zero_grad()\n",
       "        loss.backward()\n",
       "        self.optimizer.step()\n",
       "        \n",
       "        return loss.item()\n",
       "\n",
       "    def add_noise(self, x, t, noise):\n",
       "        return (\n",
       "            self.alphas_cumprod[t, None, None, None].sqrt() * x +\n",
       "            (1 - self.alphas_cumprod[t, None, None, None]).sqrt() * noise\n",
       "        )\n",
       "\n",
       "# Training loop\n",
       "diffusion = DiffusionModel()\n",
       "\n",
       "for epoch in range(num_epochs):\n",
       "    total_loss = 0\n",
       "    for batch in train_loader:\n",
       "        x, _ = batch\n",
       "        x = x.to(device)\n",
       "        loss = diffusion.train_step(x)\n",
       "        total_loss += loss\n",
       "    \n",
       "    avg_loss = total_loss / len(train_loader)\n",
       "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
       "\n",
       "print(\"Training finished!\")\n",
       "```\n",
       "\n",
       "This code does the following:\n",
       "\n",
       "1. Sets up the necessary imports and hyperparameters.\n",
       "2. Loads the CIFAR10 dataset.\n",
       "3. Defines a simple U-Net model as the neural network for the diffusion process.\n",
       "4. Creates a `DiffusionModel` class that handles the training process, including adding noise to images and predicting the noise.\n",
       "5. Implements a training loop that runs for a specified number of epochs.\n",
       "\n",
       "Note that this is a very basic implementation and lacks many features of state-of-the-art diffusion models, such as:\n",
       "\n",
       "- More complex network architectures\n",
       "- Attention mechanisms\n",
       "- Improved sampling techniques\n",
       "- Learning rate scheduling\n",
       "- EMA (Exponential Moving Average) of model weights\n",
       "- Advanced noise schedules\n",
       "\n",
       "To create a more advanced diffusion model, you'd need to incorporate these features and possibly use a more sophisticated dataset. However, this simple example should give you a starting point to understand the basic concepts and structure of a diffusion model implementation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec43dfd",
   "metadata": {},
   "source": [
    "## Using the `anthropic` Python SDK with Bedrock\n",
    "\n",
    "there is a better way of interacting with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6e1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"anthropic[bedrock]\" instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "980a297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04c-4e4b-79d3-99f7-77738e6a6442\n"
     ]
    }
   ],
   "source": [
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "client = AnthropicBedrock(\n",
    "    aws_region=\"us-east-1\",\n",
    ")\n",
    "\n",
    "output_message = client.messages.create(\n",
    "    model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006c1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today? I'm here to help with any questions or topics you'd like to discuss."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(output_message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29350cb",
   "metadata": {},
   "source": [
    "We still should probably refactor this code to a higher level function to call claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728f5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def format_prompt_anthropic(prompt: str) -> list[dict]:\n",
    "    return [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "@weave.op\n",
    "def call_claude_bis(prompt: str, model_id: str, max_tokens: int=400) -> str:\n",
    "    \"Call Bedrock Claude using the anthropic Python SDK\"\n",
    "    messages = format_prompt_anthropic(prompt)\n",
    "    response_body = client.messages.create(\n",
    "        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        max_tokens=256,\n",
    "        messages=messages)\n",
    "    return response_body.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74b0f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04c-5d4a-7eb1-aea8-25571a2daa0a\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In French, you can say:\n",
       "\n",
       "\"C'est vraiment pratique.\"\n",
       "\n",
       "Pronunciation guide:\n",
       "- \"C'est\" is pronounced like \"say\"\n",
       "- \"vraiment\" is pronounced \"vray-mahn\"\n",
       "- \"pratique\" is pronounced \"pra-teek\"\n",
       "\n",
       "This phrase translates directly to \"This is really practical\" or \"This is really handy\" in English. It's a common expression used to describe something that is very useful or convenient."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = call_claude_bis(\"How do I say: This is really handy, in french?\", model_id)\n",
    "mprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a4b20",
   "metadata": {},
   "source": [
    "## Evaluation driven development\n",
    "\n",
    "When working with LLMs, it is important to evaluate the quality of the model's responses.\n",
    "\n",
    "We can use Weave [`Evaluation`](https://wandb.github.io/weave/tutorial-eval) to build rigorous, apples-to-apples evaluations for language model use cases.\n",
    "\n",
    "Let's evaluate the models on the [Factual Inconsistency Benchmark](https://arxiv.org/abs/2211.08412v1) challenging dataset to improve check model performance to detect hallucination by identifying inconsistencies between a piece of text and a \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56878415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"./data\")\n",
    "NUM_SAMPLES = 20\n",
    "\n",
    "def read_jsonl(path):\n",
    "    \"returns a list of dictionaries\"\n",
    "    with open(path, 'r') as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "fib_ds = random.sample(read_jsonl(DATA_PATH / \"fib-val.jsonl\"), NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed6bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'More places will also be made available at all of Scotland\\'s teacher education universities.\\nThe increase of 60 primary and 200 secondary student teacher places will bring the total intake next year to 3,490.\\nThe government said it was the fifth consecutive annual increase.\\nA campaign was launched in September to try to encourage more people to enter the teaching profession in Scotland.\\nThe Scottish government\\'s #inspiringteachers campaign is focusing on science, technology, engineering and maths.\\nMinisters are also asking the new Strategic Board for Teacher Education to consider whether further actions are needed \"to make sure we have the right numbers of teachers in our schools\".\\nIn September, the leaders of seven councils called for a national taskforce to be set up to help deal with teacher recruitment problems.\\nThey made the call at a summit on tackling teacher shortages in northern and rural parts of Scotland.\\nStudent teacher places next year:\\n‚Ä¢ 1,230 post-graduate primary places - 60 more than last year\\'s target\\n‚Ä¢ 710 undergraduate primary places\\n‚Ä¢ 1,350 secondary places - up by 185 on last year\\'s target\\n‚Ä¢ 200 undergraduate secondary places - 15 more than last year\\'s target\\nEducation Secretary Angela Constance said: \"We want to make sure we have the right number of skilled teachers in our schools to help all of our young people to succeed.\\n\"That\\'s why we worked with local authorities to maintain teacher numbers this year and aim to do the same again next year, with a further ¬£51m funding.\\n\"And it\\'s why we are increasing student places for the fifth year in a row, targeting them at areas where they are needed most such as Aberdeen and Highlands and Islands universities.\\n\"We have upped last year\\'s student teacher targets for science, technology, engineering and maths and we know these will be challenging for the universities to meet.\\n\"I will be asking the new Strategic Board for Teacher Education to look at our workforce planning, particularly in the secondary sector, to consider whether there is more we can do.\\n\"We also launched a teacher recruitment campaign in September with a focus on the Stem subjects and we are working with the universities to maximise its impact.\"',\n",
       " 'hypothesis': 'The Scottish government has announced that it is making more than ¬£2m available to train an extra 260 teachers next year.',\n",
       " 'target': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303469d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_prompt = \"\"\"You are an expert to detect factual inconsistencies and hallucinations. \n",
    "You will be given a document and a summary.\n",
    "- Carefully read the full document and the provided summary.\n",
    "- Identify Factual Inconsistencies: any statements in the summary that are not supported by or contradict the information in the document.\n",
    "Factually Inconsistent: If any statement in the summary is not supported by or contradicts the document, label it as 0\n",
    "Factually Consistent: If all statements in the summary are supported by the document, label it as 1\n",
    "\n",
    "Highlight or list the specific statements in the summary that are inconsistent.\n",
    "Provide a brief explanation of why each highlighted statement is inconsistent with the document.\n",
    "\n",
    "Return in JSON format with `consistency` and a `reason` for the given choice. Encode special chars properly.\n",
    "\n",
    "Document: \n",
    "{premise}\n",
    "Summary: \n",
    "{hypothesis}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c43df7",
   "metadata": {},
   "source": [
    "we will use [`instructor`](https://github.com/jxnl/instructor) to get concsisten structured output from Claude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd99a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04c-6f52-7b31-8f08-967a39027b3a\n"
     ]
    }
   ],
   "source": [
    "class ModelOutput(BaseModel):\n",
    "    consistency: int\n",
    "    reason: str\n",
    "\n",
    "# we need to patch the client with instructor to get structured output\n",
    "inst_client = instructor.from_anthropic(client)\n",
    "\n",
    "premise = fib_ds[3][\"premise\"]\n",
    "hypothesis = fib_ds[3][\"hypothesis\"]\n",
    "\n",
    "prompt = fib_prompt.format(premise=premise, hypothesis=hypothesis)\n",
    "messages = format_prompt_anthropic(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd48ac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an expert to detect factual inconsistencies and '\n",
      "             'hallucinations. \\n'\n",
      "             'You will be given a document and a summary.\\n'\n",
      "             '- Carefully read the full document and the provided summary.\\n'\n",
      "             '- Identify Factual Inconsistencies: any statements in the '\n",
      "             'summary that are not supported by or contradict the information '\n",
      "             'in the document.\\n'\n",
      "             'Factually Inconsistent: If any statement in the summary is not '\n",
      "             'supported by or contradicts the document, label it as 0\\n'\n",
      "             'Factually Consistent: If all statements in the summary are '\n",
      "             'supported by the document, label it as 1\\n'\n",
      "             '\\n'\n",
      "             'Highlight or list the specific statements in the summary that '\n",
      "             'are inconsistent.\\n'\n",
      "             'Provide a brief explanation of why each highlighted statement is '\n",
      "             'inconsistent with the document.\\n'\n",
      "             '\\n'\n",
      "             'Return in JSON format with `consistency` and a `reason` for the '\n",
      "             'given choice. Encode special chars properly.\\n'\n",
      "             '\\n'\n",
      "             'Document: \\n'\n",
      "             \"More places will also be made available at all of Scotland's \"\n",
      "             'teacher education universities.\\n'\n",
      "             'The increase of 60 primary and 200 secondary student teacher '\n",
      "             'places will bring the total intake next year to 3,490.\\n'\n",
      "             'The government said it was the fifth consecutive annual '\n",
      "             'increase.\\n'\n",
      "             'A campaign was launched in September to try to encourage more '\n",
      "             'people to enter the teaching profession in Scotland.\\n'\n",
      "             \"The Scottish government's #inspiringteachers campaign is \"\n",
      "             'focusing on science, technology, engineering and maths.\\n'\n",
      "             'Ministers are also asking the new Strategic Board for Teacher '\n",
      "             'Education to consider whether further actions are needed \"to '\n",
      "             'make sure we have the right numbers of teachers in our '\n",
      "             'schools\".\\n'\n",
      "             'In September, the leaders of seven councils called for a '\n",
      "             'national taskforce to be set up to help deal with teacher '\n",
      "             'recruitment problems.\\n'\n",
      "             'They made the call at a summit on tackling teacher shortages in '\n",
      "             'northern and rural parts of Scotland.\\n'\n",
      "             'Student teacher places next year:\\n'\n",
      "             \"‚Ä¢ 1,230 post-graduate primary places - 60 more than last year's \"\n",
      "             'target\\n'\n",
      "             '‚Ä¢ 710 undergraduate primary places\\n'\n",
      "             \"‚Ä¢ 1,350 secondary places - up by 185 on last year's target\\n\"\n",
      "             \"‚Ä¢ 200 undergraduate secondary places - 15 more than last year's \"\n",
      "             'target\\n'\n",
      "             'Education Secretary Angela Constance said: \"We want to make sure '\n",
      "             'we have the right number of skilled teachers in our schools to '\n",
      "             'help all of our young people to succeed.\\n'\n",
      "             '\"That\\'s why we worked with local authorities to maintain '\n",
      "             'teacher numbers this year and aim to do the same again next '\n",
      "             'year, with a further ¬£51m funding.\\n'\n",
      "             '\"And it\\'s why we are increasing student places for the fifth '\n",
      "             'year in a row, targeting them at areas where they are needed '\n",
      "             'most such as Aberdeen and Highlands and Islands universities.\\n'\n",
      "             '\"We have upped last year\\'s student teacher targets for science, '\n",
      "             'technology, engineering and maths and we know these will be '\n",
      "             'challenging for the universities to meet.\\n'\n",
      "             '\"I will be asking the new Strategic Board for Teacher Education '\n",
      "             'to look at our workforce planning, particularly in the secondary '\n",
      "             'sector, to consider whether there is more we can do.\\n'\n",
      "             '\"We also launched a teacher recruitment campaign in September '\n",
      "             'with a focus on the Stem subjects and we are working with the '\n",
      "             'universities to maximise its impact.\"\\n'\n",
      "             'Summary: \\n'\n",
      "             'The Scottish government has announced that it is making more '\n",
      "             'than ¬£2m available to train an extra 260 teachers next year.\\n',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02f16dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaudeJudge(weave.Model):\n",
    "    model_id: str\n",
    "    max_tokens: int=1000\n",
    "    system_message: str = \"You are a helpful assistant and expert on extracting information in JSON format. Encode special chars properly.\"\n",
    "    prompt_template: str = fib_prompt\n",
    "\n",
    "    @weave.op\n",
    "    def apply_prompt_template(self, premise:str, hypothesis:str) -> str:\n",
    "        return self.prompt_template.format(premise=premise, hypothesis=hypothesis)\n",
    "\n",
    "    @weave.op\n",
    "    def predict(self, premise:str, hypothesis:str) -> ModelOutput:\n",
    "        prompt = self.apply_prompt_template(premise, hypothesis)\n",
    "        messages = format_prompt_anthropic(prompt)\n",
    "        structured_output = inst_client.messages.create(\n",
    "            model=self.model_id,\n",
    "            max_tokens=self.max_tokens,\n",
    "            system=self.system_message,\n",
    "            messages=messages,\n",
    "            response_model=ModelOutput)\n",
    "        return structured_output.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0266c8",
   "metadata": {},
   "source": [
    "Let's try the model on a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c9f2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/aws-genai/r/call/0192a04d-c9b8-7ce0-a577-d820aa9296ff\n",
      "{'consistency': 1,\n",
      " 'reason': 'The summary accurately reflects the key information provided in '\n",
      "           'the document. It states that the Scottish government is making '\n",
      "           'more places available to train an extra 260 teachers next year, '\n",
      "           'which aligns with the details in the document about the increase '\n",
      "           'in primary and secondary student teacher places.'}\n"
     ]
    }
   ],
   "source": [
    "haiku = ClaudeJudge(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\")\n",
    "response = haiku.predict(premise=fib_ds[3][\"premise\"], hypothesis=fib_ds[3][\"hypothesis\"])\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d8080",
   "metadata": {},
   "source": [
    "### Running the Evaluation\n",
    "\n",
    "To do an evaluation, we will need:\n",
    "- A dataset\n",
    "- A model to evalute\n",
    "- A scorer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a32cac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model_output, target):\n",
    "    class_model_output = model_output.get('consistency') if model_output else None\n",
    "    return {\"accuracy\": class_model_output == target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a2df28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = weave.Evaluation(dataset=fib_ds, scorers=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ef399ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.5104421973228455</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m14\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m4.5104421973228455\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'consistency': {'mean': 0.6}},\n",
       " 'accuracy': {'accuracy': {'true_count': 14, 'true_fraction': 0.7}},\n",
       " 'model_latency': {'mean': 4.5104421973228455}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await evaluation.evaluate(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69c72c",
   "metadata": {},
   "source": [
    "Let's try the bigger brother `sonnet-3.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24e688ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.396758449077605</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.4\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m8.396758449077605\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'consistency': {'mean': 0.4}},\n",
       " 'accuracy': {'accuracy': {'true_count': 16, 'true_fraction': 0.8}},\n",
       " 'model_latency': {'mean': 8.396758449077605}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnet = ClaudeJudge(model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\")\n",
    "await evaluation.evaluate(sonnet)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
