{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a26a16-79e4-4635-83f0-b9d39fac8282",
   "metadata": {},
   "source": [
    "# Using Weights & Biases `Weave` with AWS `Bedrock`\n",
    "\n",
    "In this notebook, you will learn to use our newly released tool for LLM practitioners.\n",
    "\n",
    "You can use [Weave](https://wandb.github.io/weave/) to:\n",
    "\n",
    "- Log and debug language model inputs, outputs, and traces\n",
    "- Build rigorous, apples-to-apples evaluations for language model use cases\n",
    "- Organize all the information generated across the LLM workflow, from experimentation and evaluations to production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1835b-7b58-41e3-b427-e6aefb6bfb5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws sso login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace11bef-d89e-4439-ad1d-00a603fd9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U weave boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b81f67-d5eb-4489-a20c-e11337d25e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from utils import mprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ab8c6-191f-4ae0-a11c-d0eac506be72",
   "metadata": {},
   "source": [
    "## Create a Weights & Biases `Weave` project to store your traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e426e5-f60e-4333-8f4a-38ceac4af672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: capecape.\n",
      "View Weave data at https://wandb.ai/capecape/aws-genai/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.weave_client.WeaveClient at 0x11e4c3150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "weave.init('aws-genai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbfcdf-780a-4b62-a235-1b32ff3b6d9f",
   "metadata": {},
   "source": [
    "Decorate your function call, that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64b3e2a-85ea-4514-8fe4-7d6fed2ff517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "@weave.op() # <- just add this 游땙\n",
    "def call_model(\n",
    "    model_id: str, \n",
    "    messages: str, \n",
    "    max_tokens: int=400,\n",
    "    ) -> dict:\n",
    "\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens})\n",
    "        \n",
    "    response = bedrock_client.invoke_model(body=body,modelId=model_id)\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899140e-11b1-4dba-be2c-6319548e7e89",
   "metadata": {},
   "source": [
    "Let's first try using the amazing `Claude Sonnet 3.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db351094-c5b7-4194-af04-b4ddc85399c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/aws-genai/r/call/01913663-5a1d-74b3-a8af-bd6e5a7520bf\n"
     ]
    }
   ],
   "source": [
    "model_id = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "messages = [{\"role\": \"user\", \n",
    "             \"content\": [\n",
    "                 {\"type\": \"text\", \n",
    "                  \"text\": (\n",
    "                        \"In Bash, how do I list all text files in the current directory \"\n",
    "                        \"(excluding subdirectories) that have been modified in the last month?\")\n",
    "                  }\n",
    "                 ]\n",
    "            }\n",
    "            ]\n",
    "\n",
    "outputs = call_model(model_id, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4916de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': [{'text': 'To list all text files in the current directory '\n",
      "                      '(excluding subdirectories) that have been modified in '\n",
      "                      'the last month using Bash, you can use the `find` '\n",
      "                      \"command combined with the `file` command. Here's how \"\n",
      "                      'you can do it:\\n'\n",
      "                      '\\n'\n",
      "                      '```bash\\n'\n",
      "                      'find . -maxdepth 1 -type f -mtime -30 -exec file {} \\\\; '\n",
      "                      '| grep text | cut -d: -f1\\n'\n",
      "                      '```\\n'\n",
      "                      '\\n'\n",
      "                      \"Let's break down this command:\\n\"\n",
      "                      '\\n'\n",
      "                      '1. `find .`: Start searching in the current directory.\\n'\n",
      "                      '\\n'\n",
      "                      '2. `-maxdepth 1`: Limit the search to the current '\n",
      "                      \"directory only (don't search subdirectories).\\n\"\n",
      "                      '\\n'\n",
      "                      '3. `-type f`: Look for files only (not directories).\\n'\n",
      "                      '\\n'\n",
      "                      '4. `-mtime -30`: Find files modified within the last 30 '\n",
      "                      'days. (Note: This is approximate; it actually means '\n",
      "                      '\"modified less than 30*24 hours ago\")\\n'\n",
      "                      '\\n'\n",
      "                      '5. `-exec file {} \\\\;`: Run the `file` command on each '\n",
      "                      'found file to determine its type.\\n'\n",
      "                      '\\n'\n",
      "                      '6. `| grep text`: Pipe the output to `grep` to filter '\n",
      "                      'for lines containing \"text\", which indicates text '\n",
      "                      'files.\\n'\n",
      "                      '\\n'\n",
      "                      '7. `| cut -d: -f1`: Use `cut` to extract just the '\n",
      "                      'filename from the `file` command output.\\n'\n",
      "                      '\\n'\n",
      "                      'If you want to be more specific about what constitutes '\n",
      "                      'a \"text file\", you might modify the `grep` part. For '\n",
      "                      'example:\\n'\n",
      "                      '\\n'\n",
      "                      '```bash\\n'\n",
      "                      'find . -maxdepth 1 -type f -mtime -30 -exec file {} \\\\; '\n",
      "                      \"| grep -E ': (ASCII|UTF-8) text' | cut -d: -f1\\n\"\n",
      "                      '```\\n'\n",
      "                      '\\n'\n",
      "                      'This version specifically looks for ASCII or UTF-8 '\n",
      "                      'encoded text files.\\n'\n",
      "                      '\\n'\n",
      "                      'Also, if you want to use calendar months instead of the '\n",
      "                      'last 30 ',\n",
      "              'type': 'text'}],\n",
      " 'id': 'msg_bdrk_013mRQVKLgmLHE21yUxXt58Q',\n",
      " 'model': 'claude-3-5-sonnet-20240620',\n",
      " 'role': 'assistant',\n",
      " 'stop_reason': 'max_tokens',\n",
      " 'stop_sequence': None,\n",
      " 'type': 'message',\n",
      " 'usage': {'input_tokens': 37, 'output_tokens': 399}}\n"
     ]
    }
   ],
   "source": [
    "pprint(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b187be1",
   "metadata": {},
   "source": [
    "realising this, we can refactor the code to be more concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f700b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def format_prompt(prompt: str) -> list[dict]:\n",
    "    messages = [{\"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \n",
    "                    \"text\": prompt}]}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def claude(model_id: str, prompt: str, max_tokens: int=400) -> str:\n",
    "    messages = format_prompt(prompt)\n",
    "    response_body = call_model(model_id, messages, max_tokens)\n",
    "    return response_body[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8edd54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/aws-genai/r/call/01913664-f8e7-7582-897c-c385c34bea0d\n"
     ]
    }
   ],
   "source": [
    "prompt = (\"Give me a super simple starting code in PyTorch for training of a diffusion model. \" \n",
    "          \"Use a minimal dataset like CIFAR10\")\n",
    "response = claude(model_id, prompt, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343aad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a simple starting code for training a diffusion model using PyTorch on the CIFAR10 dataset. This example uses a basic U-Net architecture for the model and implements a simplified diffusion process:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "from torchvision import datasets, transforms\n",
       "from torch.utils.data import DataLoader\n",
       "import numpy as np\n",
       "\n",
       "# Hyperparameters\n",
       "n_epochs = 100\n",
       "batch_size = 64\n",
       "image_size = 32\n",
       "channels = 3\n",
       "time_steps = 1000\n",
       "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "\n",
       "# Load CIFAR10 dataset\n",
       "transform = transforms.Compose([\n",
       "    transforms.ToTensor(),\n",
       "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
       "])\n",
       "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
       "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
       "\n",
       "# Simple U-Net model\n",
       "class SimpleUNet(nn.Module):\n",
       "    def __init__(self):\n",
       "        super(SimpleUNet, self).__init__()\n",
       "        self.down1 = nn.Conv2d(channels, 64, 3, padding=1)\n",
       "        self.down2 = nn.Conv2d(64, 128, 3, padding=1)\n",
       "        self.up1 = nn.ConvTranspose2d(128, 64, 3, padding=1)\n",
       "        self.up2 = nn.ConvTranspose2d(64, channels, 3, padding=1)\n",
       "        self.time_mlp = nn.Linear(1, 64)\n",
       "\n",
       "    def forward(self, x, t):\n",
       "        t = self.time_mlp(t.unsqueeze(-1)).view(-1, 64, 1, 1)\n",
       "        x1 = self.down1(x)\n",
       "        x2 = self.down2(nn.functional.relu(x1))\n",
       "        x3 = self.up1(nn.functional.relu(x2))\n",
       "        x3 = x3 + t\n",
       "        return self.up2(nn.functional.relu(x3 + x1))\n",
       "\n",
       "# Diffusion model\n",
       "class DiffusionModel:\n",
       "    def __init__(self, model, beta_start=1e-4, beta_end=0.02):\n",
       "        self.model = model\n",
       "        self.betas = torch.linspace(beta_start, beta_end, time_steps)\n",
       "        self.alphas = 1 - self.betas\n",
       "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
       "\n",
       "    def noise_images(self, x, t):\n",
       "        sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod[t])\n",
       "        sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod[t])\n",
       "        epsilon = torch.randn_like(x)\n",
       "        return sqrt_alphas_cumprod.view(-1, 1, 1, 1) * x + sqrt_one_minus_alphas_cumprod.view(-1, 1, 1, 1) * epsilon, epsilon\n",
       "\n",
       "    def train_step(self, x):\n",
       "        t = torch.randint(0, time_steps, (x.shape[0],)).to(device)\n",
       "        noisy_x, noise = self.noise_images(x, t)\n",
       "        predicted_noise = self.model(noisy_x, t.float() / time_steps)\n",
       "        return nn.functional.mse_loss(predicted_noise, noise)\n",
       "\n",
       "# Initialize model and optimizer\n",
       "model = SimpleUNet().to(device)\n",
       "diffusion = DiffusionModel(model)\n",
       "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
       "\n",
       "# Training loop\n",
       "for epoch in range(n_epochs):\n",
       "    for batch in dataloader:\n",
       "        optimizer.zero_grad()\n",
       "        x = batch[0].to(device)\n",
       "        loss = diffusion.train_step(x)\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss.item():.4f}\")\n",
       "\n",
       "# Save the model\n",
       "torch.save(model.state_dict(), \"diffusion_model.pth\")\n",
       "```\n",
       "\n",
       "This code provides a basic implementation of a diffusion model using PyTorch. It includes:\n",
       "\n",
       "1. Loading the CIFAR10 dataset\n",
       "2. A simple U-Net architecture\n",
       "3. A basic diffusion process\n",
       "4. A training loop\n",
       "\n",
       "Note that this is a minimal example and may not produce high-quality results. Real-world diffusion models typically use more complex architectures, longer training times, and additional techniques to improve performance.\n",
       "\n",
       "To run this code, you'll need to have PyTorch and torchvision installed. You can improve the model by:\n",
       "\n",
       "1. Using a more sophisticated U-Net architecture\n",
       "2. Implementing techniques like attention mechanisms\n",
       "3. Using a learning rate scheduler\n",
       "4. Implementing sampling for image generation\n",
       "5. Adding more layers and increasing the model's capacity\n",
       "\n",
       "Remember that training diffusion models can be computationally expensive and may require a GPU for reasonable training times."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec43dfd",
   "metadata": {},
   "source": [
    "## Using the `anthropic` Python SDK with Bedrock\n",
    "\n",
    "there is a better way of interacting with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"anthropic[bedrock]\" instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980a297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/aws-genai/r/call/01913665-d022-7bb3-8694-0ce7b014821b\n"
     ]
    }
   ],
   "source": [
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "client = AnthropicBedrock(\n",
    "    aws_region=\"us-east-1\",\n",
    ")\n",
    "\n",
    "output_message = client.messages.create(\n",
    "    model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006c1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today? I'm here to help with any questions you might have or tasks you need help with. Feel free to ask me about a wide range of topics or let me know if you need any specific information or guidance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(output_message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29350cb",
   "metadata": {},
   "source": [
    "We still should probably refactor this code to a higher level function to call claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "728f5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def call_claude_bis(prompt: str, model_id: str, max_tokens: int=400) -> str:\n",
    "    \"Call Bedrock Claude using the anthropic Python SDK\"\n",
    "    messages = format_prompt(prompt)\n",
    "    response_body = client.messages.create(\n",
    "        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        max_tokens=256,\n",
    "        messages=messages)\n",
    "    return response_body.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b0f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/aws-genai/r/call/01913668-51ac-7f13-99ce-7a90ae606371\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In French, you can say:\n",
       "\n",
       "\"C'est vraiment pratique.\"\n",
       "\n",
       "Pronunciation guide:\n",
       "\"Say vray-mahn pra-teek\"\n",
       "\n",
       "This phrase translates directly to \"This is really practical\" or \"This is really handy\" in English. It's a common expression used to describe something that is very useful or convenient.\n",
       "\n",
       "Alternatively, you could also say:\n",
       "\n",
       "\"C'est tr칟s utile.\" (This is very useful)\n",
       "Pronunciation: \"Say tray oo-teel\"\n",
       "\n",
       "Both expressions convey the same meaning of something being really handy or useful."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = call_claude_bis(\"How do I say: This is really handy, in french?\", model_id)\n",
    "mprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a4b20",
   "metadata": {},
   "source": [
    "## Evaluation driven development\n",
    "\n",
    "When working with LLMs, it is important to evaluate the quality of the model's responses.\n",
    "\n",
    "We can use Weave [`Evaluation`](https://wandb.github.io/weave/tutorial-eval) to build rigorous, apples-to-apples evaluations for language model use cases.\n",
    "\n",
    "Let's evaluate the models on the [Factual Inconsistency Benchmark](https://arxiv.org/abs/2211.08412v1) challenging dataset to improve check model performance to detect hallucination by identifying inconsistencies between a piece of text and a \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56878415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"./data\")\n",
    "NUM_SAMPLES = 20\n",
    "\n",
    "def read_jsonl(path):\n",
    "    \"returns a list of dictionaries\"\n",
    "    with open(path, 'r') as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "fib_ds = random.sample(read_jsonl(DATA_PATH / \"fib-val.jsonl\"), NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed6bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Police were called to an address in Holland Street at about 16:15 on Wednesday where they found the body of James Chadwick, who was from the city.\\nHe had a number of unexplained injuries.\\nFollowing the results of a post-mortem examination, his death is now being treated as murder.\\nOfficers have been carrying out door-to-door inquiries and reviewing CCTV images from the area.\\nDet Ch Insp Iain Smith, of Police Scotland, said: \"This investigation is at an early stage and it is important we establish what has happened which led to James Chadwick losing his life.\\n\"Our inquiries so far have established that Mr Chadwick was last seen on Monday 31 August and we\\'re appealing to anyone who has any knowledge of his movements since 31 August to contact police as a matter of urgency.\"',\n",
       " 'hypothesis': 'A murder investigation has been launched following the death of a man in Holland Street.',\n",
       " 'target': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "303469d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_prompt = \"\"\"You are an expert to detect factual inconsistencies and hallucinations. \n",
    "You will be given a document and a summary.\n",
    "- Carefully read the full document and the provided summary.\n",
    "- Identify Factual Inconsistencies: any statements in the summary that are not supported by or contradict the information in the document.\n",
    "Factually Inconsistent: If any statement in the summary is not supported by or contradicts the document, label it as 0\n",
    "Factually Consistent: If all statements in the summary are supported by the document, label it as 1\n",
    "\n",
    "Highlight or list the specific statements in the summary that are inconsistent.\n",
    "Provide a brief explanation of why each highlighted statement is inconsistent with the document.\n",
    "\n",
    "Return in JSON format with `consistency` and a `reason` for the given choice. Encode special chars properly.\n",
    "\n",
    "Document: \n",
    "{premise}\n",
    "Summary: \n",
    "{hypothesis}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c43df7",
   "metadata": {},
   "source": [
    "we will use [`instructor`](https://github.com/jxnl/instructor) to get concsisten structured output from Claude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd99a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput(BaseModel):\n",
    "    consistency: int\n",
    "    reason: str\n",
    "\n",
    "# we need to patch the client with instructor to get structured output\n",
    "inst_client = instructor.from_anthropic(client)\n",
    "\n",
    "class ClaudeJudge(weave.Model):\n",
    "    model_id: str\n",
    "    max_tokens: int=1000\n",
    "    system_message: str = \"You are a helpful assistant and expert on extracting information in JSON format. Encode special chars properly.\"\n",
    "    prompt_template: str = fib_prompt\n",
    "\n",
    "    @weave.op\n",
    "    def apply_prompt_template(self, premise:str, hypothesis:str) -> str:\n",
    "        return self.prompt_template.format(premise=premise, hypothesis=hypothesis)\n",
    "\n",
    "    @weave.op\n",
    "    def predict(self, premise:str, hypothesis:str, **kwargs) -> int:\n",
    "        prompt = self.apply_prompt_template(premise, hypothesis)\n",
    "        messages = format_prompt(prompt)\n",
    "        structured_output = inst_client.messages.create(\n",
    "            model=self.model_id,\n",
    "            max_tokens=self.max_tokens,\n",
    "            system=self.system_message,\n",
    "            messages=messages,\n",
    "            response_model=ModelOutput)\n",
    "        return structured_output.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0266c8",
   "metadata": {},
   "source": [
    "Let's try the model on a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c9f2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/aws-genai/r/call/01913668-da21-7d42-bd3f-8d08ffa3890b\n",
      "{'consistency': 1,\n",
      " 'reason': 'The summary is factually consistent with the information provided '\n",
      "           'in the document. The summary accurately states that a murder '\n",
      "           'investigation has been launched following the death of a man in '\n",
      "           'Holland Street, which is supported by the details in the document.'}\n"
     ]
    }
   ],
   "source": [
    "haiku = ClaudeJudge(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\")\n",
    "response = haiku.predict(**fib_ds[3])\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d8080",
   "metadata": {},
   "source": [
    "### Running the Evaluation\n",
    "\n",
    "To do an evaluation, we will need:\n",
    "- A dataset\n",
    "- A model to evalute\n",
    "- A scorer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a32cac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model_output, target):\n",
    "    class_model_output = model_output.get('consistency') if model_output else None\n",
    "    return {\"accuracy\": class_model_output == target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a2df28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = weave.Evaluation(dataset=fib_ds, scorers=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ef399ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.588719141483307</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m12\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.588719141483307\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'consistency': {'mean': 0.6}},\n",
       " 'accuracy': {'accuracy': {'true_count': 12, 'true_fraction': 0.6}},\n",
       " 'model_latency': {'mean': 3.588719141483307}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await evaluation.evaluate(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69c72c",
   "metadata": {},
   "source": [
    "Let's try the bigger brother `sonnet-3.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24e688ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.258974945545196</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m14\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m7.258974945545196\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'consistency': {'mean': 0.6}},\n",
       " 'accuracy': {'accuracy': {'true_count': 14, 'true_fraction': 0.7}},\n",
       " 'model_latency': {'mean': 7.258974945545196}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnet = ClaudeJudge(model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\")\n",
    "await evaluation.evaluate(sonnet)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
