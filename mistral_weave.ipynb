{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a26a16-79e4-4635-83f0-b9d39fac8282",
   "metadata": {},
   "source": [
    "# Using Weights & Biases Weave with AWS Bedrock\n",
    "\n",
    "In this notebook you will learn to use our newly realeased tool for the LLM practitioner\n",
    "\n",
    "You can use [Weave](https://wandb.github.io/weave/) to:\n",
    "\n",
    "- Log and debug language model inputs, outputs, and traces\n",
    "- Build rigorous, apples-to-apples evaluations for language model use cases\n",
    "- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1835b-7b58-41e3-b427-e6aefb6bfb5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace11bef-d89e-4439-ad1d-00a603fd9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq wandb weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b81f67-d5eb-4489-a20c-e11337d25e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a8001-81ec-439e-a425-6c98ffcb5c27",
   "metadata": {},
   "source": [
    "## log to your W&B account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab5831-7331-4ef7-a212-d618bcdded1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ab8c6-191f-4ae0-a11c-d0eac506be72",
   "metadata": {},
   "source": [
    "## create a W&B project to store your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e426e5-f60e-4333-8f4a-38ceac4af672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as W&B user capecape.\n",
      "View Weave data at https://wandb.ai/capecape/bedrock-weave/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.init('bedrock-weave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbfcdf-780a-4b62-a235-1b32ff3b6d9f",
   "metadata": {},
   "source": [
    "Decorate your function call, that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c64b3e2a-85ea-4514-8fe4-7d6fed2ff517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@weave.op() # <- just add this 游땙\n",
    "def generate_text(\n",
    "    model_id: str, \n",
    "    prompt: str, \n",
    "    max_tokens: int=400,\n",
    "    temperature: float=0.7,\n",
    "    top_p: float=0.7,\n",
    "    top_k: int=50,\n",
    ") -> dict:\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "    })\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    outputs = response_body.get('outputs')\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899140e-11b1-4dba-be2c-6319548e7e89",
   "metadata": {},
   "source": [
    "Let's first try using Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db351094-c5b7-4194-af04-b4ddc85399c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/bedrock-weave/r/call/5640fce1-e154-4d1e-80f4-82dda0050d0b\n",
      "Output 1\n",
      "----------\n",
      "Text:\n",
      " Title: Vegan Carbonara with Creamy Cashew Sauce\n",
      "\n",
      "Prep Time: 15 minutes\n",
      "Cook Time: 10 minutes\n",
      "Total Time: 25 minutes\n",
      "\n",
      "Servings: 4\n",
      "\n",
      "Ingredients:\n",
      "- 12 oz (340g) spaghetti or your preferred pasta\n",
      "- 1 1/2 cups (375ml) unsweetened almond or soy milk\n",
      "- 1 1/2 cups (180g) raw cashews, soaked in water for at least 2 hours\n",
      "- 1/2 cup (120ml) vegetable broth\n",
      "- 1/4 cup (60g) nutritional yeast\n",
      "- 2 tbsp (30ml) olive oil, divided\n",
      "- 1 tbsp (15ml) lemon juice\n",
      "- 1 tbsp (15ml) apple cider vinegar\n",
      "- 1 tsp (5ml) garlic powder\n",
      "- 1 tsp (5ml) onion powder\n",
      "- 1 tsp (5ml) smoked paprika (optional)\n",
      "- 1 tsp (5ml) salt, or to taste\n",
      "- 1/2 tsp (2.5ml) black pepper, or to taste\n",
      "- 1/2 cup (120g) cooked crumbled tofu or vegan bacon (optional)\n",
      "- 1/2 cup (120g) chopped fresh parsley\n",
      "- 1/4 cup (60g) chopped scallions\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Cook pasta according to package instructions. Drain and set aside, reserving 1 cup (240ml) of pasta water.\n",
      "\n",
      "2. In a blender, combine soaked cashews\n",
      "\n",
      "Stop reason: length\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = 'mistral.mistral-7b-instruct-v0:2'\n",
    "\n",
    "prompt = \"\"\"<s>[INST] Create a Vegan Carbonara Recipe[/INST]\"\"\"\n",
    "\n",
    "outputs = generate_text(model_id, prompt)\n",
    "\n",
    "for index, output in enumerate(outputs):\n",
    "\n",
    "    print(f\"Output {index + 1}\\n----------\")\n",
    "    print(f\"Text:\\n{output['text']}\\n\")\n",
    "    print(f\"Stop reason: {output['stop_reason']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba9053-cb81-4950-aaa0-91d2f7ff552f",
   "metadata": {},
   "source": [
    "## Translation project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c98752-6596-4429-a58f-18cdaab5f98f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's use these powerful LLMs to translate the documentation of Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "974487f2-471d-4ab2-b0c3-587d97327339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "# Instructions\n",
    "\n",
    "You are a documentation translation assistant from English to {output_language}. We are translating valid docusaurus flavored markdown. Some rules to remember:\n",
    "\n",
    "- Do not add extra blank lines.\n",
    "- The results must be valid docusaurus markdown\n",
    "- It is important to maintain the accuracy of the contents but we don't want the output to read like it's been translated. So instead of translating word by word, prioritize naturalness and ease of communication.\n",
    "- In code blocks, just translate the comments and leave the code as is.\n",
    "\n",
    "\n",
    "## Formatting Rules\n",
    "\n",
    "Do not translate target markdown links. Never translate the part of the link inside (). For instance here [https://wandb.ai/site](https://wandb.ai/site) do not translate anything, but on this, you should translate the [] part:\n",
    "[track metrics](./guides/track), [create logs](./guides/artifacts).\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "Here is a chunk of documentation in docusaurus Markdown format to translate. Return the translation only, without adding anything else. \n",
    "<Markdown start>\n",
    "{md_chunk}\n",
    "<End of Markdown>\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class PromptTemplate:\n",
    "    system_prompt: str\n",
    "    human_prompt: str\n",
    "    language: str\n",
    "    \n",
    "    def format_mistral_instruct(self, md_chunk):\n",
    "        \"A formatting function for Mistral Instruct models\"\n",
    "        system_prompt = self.system_prompt.format(output_language=self.language)\n",
    "        human_prompt = self.human_prompt.format(md_chunk=md_chunk)\n",
    "        prompt = f\"<s>[INST] {system_prompt}\\n{human_prompt}[/INST]\"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f77ef2-9514-4f15-8bc6-65d0e3372a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(system_prompt, human_prompt, \"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ff6fd-f9f4-4769-9811-01f462bbd404",
   "metadata": {},
   "source": [
    "let's read 2 files from our documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81557531-0135-4f44-b26c-8b7e28520cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [p.read_text() for p in Path(\"./docs\").iterdir() if p.suffix == \".md\"]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d90b8-e64a-4973-a37d-5ef2897c9871",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can now call the model with this new prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78733554-fe65-4173-8bd0-b4f1998a196e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/bedrock-weave/r/call/7d6a04b0-479b-43d7-a7af-63301407d647\n",
      "Text:\n",
      " ---\n",
      "description: Inicio r치pido de W&B.\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "import Tabs from '@theme/Tabs';\n",
      "import TabItem from '@theme/TabItem';\n",
      "\n",
      "# Inicio r치pido\n",
      "\n",
      "Instale W&B y monitoree tus experimentos de aprendizaje autom치tico en minutos.\n",
      "\n",
      "## 1. Crea una cuenta y Instala W&B\n",
      "Antes de empezar, aseg칰rate de crear una cuenta y de instalar W&B:\n",
      "\n",
      "1. [Reg칤strate](https://wandb.ai/site) para una cuenta gratuita en [https://wandb.ai/site](https://wandb.ai/site) y luego inicia sesi칩n en tu cuenta de wandb.  \n",
      "2. Instala la biblioteca wandb en tu m치quina en un entorno Python 3 usando [`pip`](https://pypi.org/project/wandb/).  \n",
      "<!-- 3. Inicia sesi칩n en la biblioteca de wandb en tu m치quina. Encontrar치s tu clave API aqu칤: [https://wandb.ai/authorize](https://wandb.ai/authorize).   -->\n",
      "\n",
      "Los siguientes fragmentos de c칩digo muestran c칩mo instalar y iniciar sesi칩n en W&B usando la CLI y la Biblioteca de Python de W&B:\n",
      "\n",
      "<Tabs\n",
      "  defaultValue=\"notebook\"\n",
      "  values={[\n",
      "    {label: 'Notebook', value: 'notebook'},\n",
      "    {label: 'L칤nea de comandos', value: 'cli'},\n",
      "  ]}>\n",
      "  <TabItem value=\"cli\">\n",
      "\n",
      "Instala la CLI y la biblioteca de Python para interactuar con la API de W&B:\n",
      "\n",
      "```\n",
      "pip install wandb\n",
      "```\n",
      "\n",
      "  </TabItem>\n",
      "  <TabItem value=\"notebook\">\n",
      "\n",
      "Instala la CLI y la biblioteca de Python para interactuar con la API de W&B:\n",
      "\n",
      "```python\n",
      "!pip install wandb\n",
      "```\n",
      "\n",
      "\n",
      "  </TabItem>\n",
      "</Tabs>\n",
      "\n",
      "## 2. Inicia sesi칩n en W&B\n",
      "\n",
      "<Tabs\n",
      "  defaultValue=\"notebook\"\n",
      "  values={[\n",
      "    {label: 'Notebook', value: 'notebook'},\n",
      "    {label: 'L칤nea de comandos', value: 'cli'},\n",
      "  ]}>\n",
      "  <TabItem value=\"cli\">\n",
      "\n",
      "Desp칰es, inicia sesi칩n en W&B:\n",
      "\n",
      "```\n",
      "wandb login\n",
      "```\n",
      "\n",
      "O si est치s usando [W&B Server:](./guides/hosting)\n",
      "\n",
      "```\n",
      "wandb login --host=http://wandb.tu-servidor-compartido.local\n",
      "```\n",
      "\n",
      "Proporciona [tu clave API](https://wandb.ai/authorize) cuando te lo soliciten.\n",
      "\n",
      "  </TabItem>\n",
      "  <TabItem value=\"notebook\">\n",
      "\n",
      "Desp칰es, importa la SDK de Python de W&B y inicia sesi칩n:\n",
      "\n",
      "```python\n",
      "wandb.login()\n",
      "```\n",
      "\n",
      "Proporciona [tu clave API](https://wandb.ai/authorize) cuando te lo soliciten.\n",
      "  </TabItem>\n",
      "</Tabs>\n",
      "\n",
      "## 3. Inicia un run y rastrea hiperpar치metros\n",
      "\n",
      "Inicializa un objeto de run de W&B en tu script o notebook de Python con [`wandb.init()`](./ref/python/run.md) y pasa un diccionario al par치metro `config` con pares clave-valor de nombres de hiperpar치metros y valores:\n",
      "\n",
      "```python\n",
      "run = wandb.init(\n",
      "    # Establece el proyecto en el que se registrar치 este run\n",
      "    project=\"mi-proyecto-genial\",\n",
      "    # Rastrea hiperpar치metros y metadatos de runs\n",
      "    config={\n",
      "        \"tasa_aprendizaje\": 0.01,\n",
      "        \"epocas\": 10,\n",
      "    })\n",
      "```\n",
      "\n",
      "<!-- ```python\n",
      "run = wandb.init(project=\"mi-proyecto-genial\")\n",
      "``` -->\n",
      "\n",
      "Un [run](./guides/runs) es la unidad b치sica de W&B. Usar치s muchos de ellos para [rastrear m칠tricas](./guides/track), [crear registros](./guides/artifacts), [crear trabajos](./guides/launch), y m치s.\n",
      "\n",
      "\n",
      "<!-- ## Rastrear m칠tricas -->\n",
      "<!-- Pasa un diccionario al par치metro `config` con pares clave-valor de nombre de hiperpar치metro y valores cuando inicializas un objeto de run:\n",
      "\n",
      "```python\n",
      "  # Rastrea hiperpar치metros y metadatos de runs\n",
      "  config={\n",
      "      \"tasa_aprendizaje\": lr,\n",
      "      \"epocas\": epochs,\n",
      "  }\n",
      "``` -->\n",
      "\n",
      "\n",
      "<!-- Utiliza [`wandb.log()`](./ref/python/log.md) para rastrear m칠tricas:\n",
      "\n",
      "```python\n",
      "wandb.log({'precisi칩n': precisi칩n, 'p칠rdida': p칠rdida})\n",
      "```\n",
      "\n",
      "Cualquier cosa que rastrees con `wandb.log` se almacena en el objeto de run m치s reciente que se inicializ칩. -->\n",
      "\n",
      "## Pasos siguientes\n",
      "\n",
      "Explora el resto del ecosistema de W&B.\n",
      "\n",
      "1. Revisa [Integraciones de W&B](guides/integrations) para aprender a integrar W&B con tu marco de aprendizaje de m치quina como PyTorch, tu biblioteca de aprendizaje de m치quina como Hugging Face, o tu servicio de aprendizaje de m치quina como SageMaker. \n",
      "2. Organiza tus runs, crea y automatiza visualizaciones, describe tus hallazgos, y comparte actualizaciones con colaboradores con [W&B Reportes](./guides/reports).\n",
      "3. Crea [Artifactos de W&B](./guides/artifacts) para rastrear conjuntos de datos, modelos, dependencias, y resultados a lo largo de tu pipeline de aprendizaje de m치quina.\n",
      "4. Busca la mejor combinaci칩n de hiperpar치metros y explora el espacio de posibles modelos con [W&B Sweeps](./guides/sweeps).\n",
      "5. Entiende tus conjuntos de datos, visualiza predicciones de modelos, y comparte insight en un [panel de control central](./guides/data-vis).\n",
      "\n",
      "\n",
      "![](/images/quickstart/wandb_demo_experiments.gif) \n",
      "\n",
      "## Preguntas comunes\n",
      "\n",
      "**D칩nde encuentro mi clave API?**\n",
      "Despu칠s de haber iniciado sesi칩n en [www.wandb.ai](https://wandb.ai), encontrar치s tu clave API en la p치gina [Autorizar](https://wandb.ai/authorize).\n",
      "\n",
      "**C칩mo uso W&B en un entorno automatizado?**\n",
      "Si est치s entrenando modelos en un entorno automatizado donde resulta inconveniente ejecutar comandos de shell, como Google's CloudML, deber칤as revisar nuestra gu칤a sobre configuraci칩n con [Variables de Entorno](guides/track/environment-variables).\n",
      "\n",
      "**Ofrecemos instalaciones locales, en el propio?**\n",
      "S칤, puedes [alojar W&B](guides/hosting/) localmente en tus propias m치quinas o en una nube privada. Intenta este r치pido tutorial de notebook para ver c칩mo. Nota, para iniciar sesi칩n en el servidor de wandb local, puedes [establecer la bandera de host](guides/hosting/how-to-guides/basic-setup) a la direcci칩n de la instancia local.  \n",
      "\n",
      "**C칩mo desactivo el registro de wandb temporalmente?**\n",
      "Si est치s probando c칩digo y quieres desactivar la sincronizaci칩n de wandb, establece la variable de entorno [`WANDB_MODE=offline`](./guides/track/environment-variables).\n",
      "\n",
      "Stop reason: stop\n",
      "\n",
      "游꼴 https://wandb.ai/capecape/bedrock-weave/r/call/33e0cfa5-a206-4cec-b5db-27f93f8677d2\n",
      "Text:\n",
      " <Markdown start>\n",
      "---\n",
      "description: >-\n",
      "  Una visi칩n general de lo que es W&B y enlaces para empezar si eres un usuario nuevo.\n",
      "slug: /guides\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "# 쯈u칠 es W&B?\n",
      "\n",
      "W&B es la plataforma de aprendizaje autom치tico para desarrolladores para construir mejores modelos m치s r치pido. Use las herramientas ligeras e interoperables de W&B para r치pidamente rastrear experimentos, versionar y iterar en conjuntos de datos, evaluar el rendimiento de modelos, reproducir modelos, visualizar resultados y detectar regresiones, y compartir hallazgos con tus colegas.\n",
      "Configure W&B en 5 minutos y luego iterar r치pidamente en tu canal de producci칩n de aprendizaje autom치tico con la confianza de que tus conjuntos de datos y modelos est치n rastreados y versionados en un sistema de registro confiable.\n",
      "\n",
      "<!-- ![](@site/static/images/general/diagram_2021.png) -->\n",
      "\n",
      "## 쮼res un nuevo usuario de W&B?\n",
      "\n",
      "Si est치s utilizando W&B por primera vez, sugieremos que explores lo siguiente:\n",
      "\n",
      "1. Experimenta W&B en acci칩n, [ejecute un proyecto de introducci칩n de Google Colab](http://wandb.me/intro).\n",
      "2. Lee a trav칠s de la [Gu칤a r치pida](../quickstart.md) para obtener una visi칩n general de c칩mo y d칩nde agregar W&B a tu c칩digo.\n",
      "3. Lee [C칩mo funciona W&B?](#c칩mo-funciona-weights--biases) Esta secci칩n proporciona una visi칩n general de los bloques de construcci칩n de W&B.\n",
      "4. Explora nuestra [Gu칤a de integraciones](./integrations/intro.md) y nuestra [Playlist de integraciones de Weave en YouTube](https://www.youtube.com/playlist?list=PLD80i8An1OEGDADxOBaH71ZwieZ9nmPGC) para obtener informaci칩n sobre c칩mo integrar W&B con tu marco de aprendizaje autom치tico preferido.\n",
      "5. Revise la [Gu칤a de referencia de API](../ref/README.md) para especificaciones t칠cnicas sobre la Biblioteca de Python de W&B, la CLI y las operaciones de Weave.\n",
      "\n",
      "## C칩mo funciona W&B?\n",
      "\n",
      "Recomendamos que leas estas secciones en este orden si eres un usuario nuevo de W&B:\n",
      "\n",
      "1. Aprende sobre [Corrida](./runs/intro.md), la unidad b치sica de computo de W&B.\n",
      "2. Cree y rastree experimentos de aprendizaje autom치tico con [Experimentos](./track/intro.md).\n",
      "3. Descubre el bloque flexible y ligero de W&B para la versionaci칩n de conjuntos de datos y modelos con [Artifacts](./artifacts/intro.md).\n",
      "4. Automatice la b칰squeda de hiperpar치metros y explore el espacio de posibles modelos con [Sweeps](./sweeps/intro.md).\n",
      "5. Administre el ciclo de vida del modelo desde el entrenamiento hasta la producci칩n con [Gesti칩n de modelos](./models/intro.md).\n",
      "6. Visualice predicciones a lo largo de versiones de modelos con nuestra [Gu칤a de visualizaci칩n de datos](./data-vis/intro.md).\n",
      "7. Organice las corridas de W&B, enmarque y automatice visualizaciones, describa tus hallazgos y compartas actualizaciones con colaboradores con [Informes](./reports/intro.md).\n",
      "\n",
      "<End of Markdown>\n",
      "\n",
      "Stop reason: stop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    output = generate_text(model_id, prompt_template.format_mistral_instruct(doc), max_tokens=2048)\n",
    "    print(f\"Text:\\n{output[0]['text']}\\n\")\n",
    "    print(f\"Stop reason: {output[0]['stop_reason']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4708c4d3-4707-42d3-b59c-1335a7f55477",
   "metadata": {},
   "source": [
    "We can improve our weave experience by creating a `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4d8f93b-a51b-47e5-a7a6-5230dce672ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from weave import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0191b0e0-f66d-4f0a-a3f5-5aa2c76dd80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MistralInstruct(Model):\n",
    "    prompt_template: PromptTemplate\n",
    "    temperature: float=0.7\n",
    "    max_tokens: int=2048\n",
    "    model_id: str='mistral.mistral-7b-instruct-v0:2'\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, document: str) -> dict:\n",
    "        output = generate_text(\n",
    "             model_id, \n",
    "             self.prompt_template.format_mistral_instruct(document), \n",
    "             temperature=self.temperature,\n",
    "             max_tokens=self.max_tokens,\n",
    "        )\n",
    "        return output[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf9ea785-c850-4780-9336-7521399e301e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MistralInstruct(prompt_template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7285ce21-6663-4293-b819-305e2ff670cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/capecape/bedrock-weave/r/call/1b4327fc-4398-46f6-9522-bffae3af0a7f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ---\\ndescription: Inicio r치pido de W&B.\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Inicio r치pido\\n\\nComience a rastrear sus experimentos de aprendizaje autom치tico en W&B en minutos.\\n\\n## 1. Crea una cuenta y instala W&B\\nAntes de empezar, cree una cuenta y instale W&B:\\n\\n1. [Reg칤strate](https://wandb.ai/site) gratis en [https://wandb.ai/site](https://wandb.ai/site) y luego inicie sesi칩n en tu cuenta de wandb.  \\n2. Instale la biblioteca wandb en tu m치quina en un entorno Python 3 usando [`pip`](https://pypi.org/project/wandb/).  \\n<!-- 3. Inicie sesi칩n en la biblioteca wandb en tu m치quina. Encuentre su clave API aqu칤: [https://wandb.ai/authorize](https://wandb.ai/authorize).   -->\\n\\nLos siguientes fragmentos de c칩digo muestran c칩mo instalar y iniciar sesi칩n en W&B usando la CLI y la biblioteca de Python:\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'L칤nea de comandos\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nInstale la CLI y la biblioteca de Python para interactuar con la API de Weights and Biases:\\n\\n```\\npip install wandb\\n```\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nInstale la CLI y la biblioteca de Python para interactuar con la API de Weights and Biases:\\n\\n```python\\n!pip install wandb\\n```\\n\\n\\n  </TabItem>\\n</Tabs>\\n\\n## 2. Inicia sesi칩n en W&B\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'L칤nea de comandos\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nDespu칠s, inicia sesi칩n en W&B:\\n\\n```\\nwandb login\\n```\\n\\nO si est치 usando [W&B Server:](./guides/hosting)\\n\\n```\\nwandb login --host=http://wandb.tu-servidor-compartido.local\\n```\\n\\nProporcione [su clave API](https://wandb.ai/authorize) cuando se solicite.\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nDespu칠s, importe la SDK de Python de W&B y inicie sesi칩n:\\n\\n```python\\nwandb.login()\\n```\\n\\nProporcione [su clave API](https://wandb.ai/authorize) cuando se solicite.\\n  </TabItem>\\n</Tabs>\\n\\n## 3. Inicia un run y rastrea hiperpar치metros\\n\\nInicie un objeto de corrida de W&B en su script o notebook de Python con [`wandb.init()`](./ref/python/run.md) y pase un diccionario al par치metro `config` con pares clave-valor de nombres de hiperpar치metros y valores:\\n\\n```python\\nrun = wandb.init(\\n    # Establezca el proyecto en el que se registrar치 esta corrida\\n    project=\"mi-proyecto-genial\",\\n    # Rastrear hiperpar치metros y metadatos de la corrida\\n    config={\\n        \"tasa_aprendizaje\": 0.01,\\n        \"epocas\": 10,\\n    })\\n```\\n\\n\\n<!-- ```python\\nrun = wandb.init(project=\"mi-proyecto-genial\")\\n``` -->\\n\\nUn [corrida](./guides/runs) es la unidad b치sica de W&B. Usar치 frecuentemente corrida para [rastrear m칠tricas](./guides/track), [crear registros](./guides/artifacts), [crear tareas](./guides/launch), y m치s.\\n\\n\\n<!-- ## Rastrear m칠tricas -->\\n<!-- Pasa un diccionario al par치metro `config` con pares clave-valor de nombre de hiperpar치metro y valores cuando inicie un objeto de corrida:\\n\\n```python\\n  # Rastrear hiperpar치metros y metadatos de la corrida\\n  config={\\n      \"tasa_aprendizaje\": lr,\\n      \"epocas\": epochs,\\n  }\\n``` -->\\n\\n\\n<!-- Use [`wandb.log()`](./ref/python/log.md) para rastrear m칠tricas:\\n\\n```python\\nwandb.log({\\'precisi칩n\\': precisi칩n, \\'p칠rdida\\': p칠rdida})\\n```\\n\\nCualquier cosa que registre con `wandb.log` se almacena en el objeto de corrida que se inici칩 recientemente. -->\\n\\n## Pasos siguientes\\n\\nExplore el resto del ecosistema de W&B.\\n\\n1. Consulte [Integraciones de W&B](guides/integrations) para aprender a integrar W&B con su framework de aprendizaje autom치tico como PyTorch, su biblioteca de machine learning como Hugging Face, o su servicio de machine learning como SageMaker. \\n2. Organice corrida, embed y automatice visualizaciones, describa sus hallazgos, y comparte actualizaciones con colaboradores con [W&B Informes](./guides/reports).\\n3. Cree [Artifactos de W&B](./guides/artifacts) para rastrear conjuntos de datos, modelos, dependencias, y resultados a lo largo de su pipeline de machine learning.\\n4. Realice b칰squeda de hiperpar치metros automatizada y explore el espacio de posibles modelos con [W&B Sweeps](./guides/sweeps).\\n5. Entenda sus conjuntos de datos, visualice predicciones de modelos, y comparte insight en un [panel de control central](./guides/data-vis).\\n\\n\\n![Muestra las p칠rdidas y precisiones que se rastrearon cada vez que se ejecut칩 el script anterior. ](/images/quickstart/quickstart_image.png)\\n\\n\\n\\n## Preguntas comunes\\n\\n**쮻칩nde encuentro mi clave API?**\\nDespu칠s de haber iniciado sesi칩n en [www.wandb.ai](https://wandb.ai), encontrar치 su clave API en la p치gina [Autorizar](https://wandb.ai/authorize).\\n\\n**쮺칩mo uso W&B en un entorno automatizado?**\\nSi est치 entrenando modelos en un entorno automatizado donde resulta inconveniente ejecutar comandos de shell, como Google\\'s CloudML, debe revisar nuestra gu칤a de configuraci칩n con [Variables de Entorno](guides/track/environment-variables).\\n\\n**쯆frecemos instalaciones locales, en la nube privada?**\\nS칤, puede [alojar W&B localmente](guides/hosting/) en sus propias m치quinas o en una nube privada, int칠ntese con este r치pido tutorial de notebook para ver c칩mo. Nota, para iniciar sesi칩n en el servidor W&B local, puede [establecer la bandera host](guides/hosting/how-to-guides/basic-setup) a la direcci칩n de la instancia local.  \\n\\n**쮺칩mo desactivo el registro de wandb temporalmente?**\\nSi est치 probando c칩digo y desea desactivar la sincronizaci칩n de wandb, establezca la variable de entorno [`WANDB_MODE=offline`](./guides/track/environment-variables).'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f3ade-72c9-46a5-ad0a-9a88f08a8c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
