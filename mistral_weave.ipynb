{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a26a16-79e4-4635-83f0-b9d39fac8282",
   "metadata": {},
   "source": [
    "# Using Weights & Biases Weave with AWS Bedrock\n",
    "\n",
    "In this notebook you will learn to use our newly realeased tool for the LLM practitioner\n",
    "\n",
    "You can use [Weave](https://wandb.github.io/weave/) to:\n",
    "\n",
    "- Log and debug language model inputs, outputs, and traces\n",
    "- Build rigorous, apples-to-apples evaluations for language model use cases\n",
    "- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1835b-7b58-41e3-b427-e6aefb6bfb5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace11bef-d89e-4439-ad1d-00a603fd9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq wandb weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b81f67-d5eb-4489-a20c-e11337d25e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a8001-81ec-439e-a425-6c98ffcb5c27",
   "metadata": {},
   "source": [
    "## log to your W&B account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab5831-7331-4ef7-a212-d618bcdded1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ab8c6-191f-4ae0-a11c-d0eac506be72",
   "metadata": {},
   "source": [
    "## create a W&B project to store your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e426e5-f60e-4333-8f4a-38ceac4af672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as W&B user capecape.\n",
      "View Weave data at https://wandb.ai/capecape/bedrock-weave/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.init('bedrock-weave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbfcdf-780a-4b62-a235-1b32ff3b6d9f",
   "metadata": {},
   "source": [
    "Decorate your function call, that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c64b3e2a-85ea-4514-8fe4-7d6fed2ff517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@weave.op() # <- just add this üòé\n",
    "def generate_text(\n",
    "    model_id: str, \n",
    "    prompt: str, \n",
    "    max_tokens: int=400,\n",
    "    temperature: float=0.7,\n",
    "    top_p: float=0.7,\n",
    "    top_k: int=50,\n",
    ") -> dict:\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "    })\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    outputs = response_body.get('outputs')\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899140e-11b1-4dba-be2c-6319548e7e89",
   "metadata": {},
   "source": [
    "Let's first try using Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db351094-c5b7-4194-af04-b4ddc85399c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/bedrock-weave/r/call/5640fce1-e154-4d1e-80f4-82dda0050d0b\n",
      "Output 1\n",
      "----------\n",
      "Text:\n",
      " Title: Vegan Carbonara with Creamy Cashew Sauce\n",
      "\n",
      "Prep Time: 15 minutes\n",
      "Cook Time: 10 minutes\n",
      "Total Time: 25 minutes\n",
      "\n",
      "Servings: 4\n",
      "\n",
      "Ingredients:\n",
      "- 12 oz (340g) spaghetti or your preferred pasta\n",
      "- 1 1/2 cups (375ml) unsweetened almond or soy milk\n",
      "- 1 1/2 cups (180g) raw cashews, soaked in water for at least 2 hours\n",
      "- 1/2 cup (120ml) vegetable broth\n",
      "- 1/4 cup (60g) nutritional yeast\n",
      "- 2 tbsp (30ml) olive oil, divided\n",
      "- 1 tbsp (15ml) lemon juice\n",
      "- 1 tbsp (15ml) apple cider vinegar\n",
      "- 1 tsp (5ml) garlic powder\n",
      "- 1 tsp (5ml) onion powder\n",
      "- 1 tsp (5ml) smoked paprika (optional)\n",
      "- 1 tsp (5ml) salt, or to taste\n",
      "- 1/2 tsp (2.5ml) black pepper, or to taste\n",
      "- 1/2 cup (120g) cooked crumbled tofu or vegan bacon (optional)\n",
      "- 1/2 cup (120g) chopped fresh parsley\n",
      "- 1/4 cup (60g) chopped scallions\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Cook pasta according to package instructions. Drain and set aside, reserving 1 cup (240ml) of pasta water.\n",
      "\n",
      "2. In a blender, combine soaked cashews\n",
      "\n",
      "Stop reason: length\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = 'mistral.mistral-7b-instruct-v0:2'\n",
    "\n",
    "prompt = \"\"\"<s>[INST] Create a Vegan Carbonara Recipe[/INST]\"\"\"\n",
    "\n",
    "outputs = generate_text(model_id, prompt)\n",
    "\n",
    "for index, output in enumerate(outputs):\n",
    "\n",
    "    print(f\"Output {index + 1}\\n----------\")\n",
    "    print(f\"Text:\\n{output['text']}\\n\")\n",
    "    print(f\"Stop reason: {output['stop_reason']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba9053-cb81-4950-aaa0-91d2f7ff552f",
   "metadata": {},
   "source": [
    "## Translation project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c98752-6596-4429-a58f-18cdaab5f98f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's use these powerful LLMs to translate the documentation of Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "974487f2-471d-4ab2-b0c3-587d97327339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "# Instructions\n",
    "\n",
    "You are a documentation translation assistant from English to {output_language}. We are translating valid docusaurus flavored markdown. Some rules to remember:\n",
    "\n",
    "- Do not add extra blank lines.\n",
    "- The results must be valid docusaurus markdown\n",
    "- It is important to maintain the accuracy of the contents but we don't want the output to read like it's been translated. So instead of translating word by word, prioritize naturalness and ease of communication.\n",
    "- In code blocks, just translate the comments and leave the code as is.\n",
    "\n",
    "\n",
    "## Formatting Rules\n",
    "\n",
    "Do not translate target markdown links. Never translate the part of the link inside (). For instance here [https://wandb.ai/site](https://wandb.ai/site) do not translate anything, but on this, you should translate the [] part:\n",
    "[track metrics](./guides/track), [create logs](./guides/artifacts).\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "Here is a chunk of documentation in docusaurus Markdown format to translate. Return the translation only, without adding anything else. \n",
    "<Markdown start>\n",
    "{md_chunk}\n",
    "<End of Markdown>\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class PromptTemplate:\n",
    "    system_prompt: str\n",
    "    human_prompt: str\n",
    "    language: str\n",
    "    \n",
    "    def format_mistral_instruct(self, md_chunk):\n",
    "        \"A formatting function for Mistral Instruct models\"\n",
    "        system_prompt = self.system_prompt.format(output_language=self.language)\n",
    "        human_prompt = self.human_prompt.format(md_chunk=md_chunk)\n",
    "        prompt = f\"<s>[INST] {system_prompt}\\n{human_prompt}[/INST]\"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f77ef2-9514-4f15-8bc6-65d0e3372a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(system_prompt, human_prompt, \"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ff6fd-f9f4-4769-9811-01f462bbd404",
   "metadata": {},
   "source": [
    "let's read 2 files from our documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81557531-0135-4f44-b26c-8b7e28520cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [p.read_text() for p in Path(\"./docs\").iterdir() if p.suffix == \".md\"]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d90b8-e64a-4973-a37d-5ef2897c9871",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can now call the model with this new prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78733554-fe65-4173-8bd0-b4f1998a196e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/bedrock-weave/r/call/7d6a04b0-479b-43d7-a7af-63301407d647\n",
      "Text:\n",
      " ---\n",
      "description: Inicio r√°pido de W&B.\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "import Tabs from '@theme/Tabs';\n",
      "import TabItem from '@theme/TabItem';\n",
      "\n",
      "# Inicio r√°pido\n",
      "\n",
      "Instale W&B y monitoree tus experimentos de aprendizaje autom√°tico en minutos.\n",
      "\n",
      "## 1. Crea una cuenta y Instala W&B\n",
      "Antes de empezar, aseg√∫rate de crear una cuenta y de instalar W&B:\n",
      "\n",
      "1. [Reg√≠strate](https://wandb.ai/site) para una cuenta gratuita en [https://wandb.ai/site](https://wandb.ai/site) y luego inicia sesi√≥n en tu cuenta de wandb.  \n",
      "2. Instala la biblioteca wandb en tu m√°quina en un entorno Python 3 usando [`pip`](https://pypi.org/project/wandb/).  \n",
      "<!-- 3. Inicia sesi√≥n en la biblioteca de wandb en tu m√°quina. Encontrar√°s tu clave API aqu√≠: [https://wandb.ai/authorize](https://wandb.ai/authorize).   -->\n",
      "\n",
      "Los siguientes fragmentos de c√≥digo muestran c√≥mo instalar y iniciar sesi√≥n en W&B usando la CLI y la Biblioteca de Python de W&B:\n",
      "\n",
      "<Tabs\n",
      "  defaultValue=\"notebook\"\n",
      "  values={[\n",
      "    {label: 'Notebook', value: 'notebook'},\n",
      "    {label: 'L√≠nea de comandos', value: 'cli'},\n",
      "  ]}>\n",
      "  <TabItem value=\"cli\">\n",
      "\n",
      "Instala la CLI y la biblioteca de Python para interactuar con la API de W&B:\n",
      "\n",
      "```\n",
      "pip install wandb\n",
      "```\n",
      "\n",
      "  </TabItem>\n",
      "  <TabItem value=\"notebook\">\n",
      "\n",
      "Instala la CLI y la biblioteca de Python para interactuar con la API de W&B:\n",
      "\n",
      "```python\n",
      "!pip install wandb\n",
      "```\n",
      "\n",
      "\n",
      "  </TabItem>\n",
      "</Tabs>\n",
      "\n",
      "## 2. Inicia sesi√≥n en W&B\n",
      "\n",
      "<Tabs\n",
      "  defaultValue=\"notebook\"\n",
      "  values={[\n",
      "    {label: 'Notebook', value: 'notebook'},\n",
      "    {label: 'L√≠nea de comandos', value: 'cli'},\n",
      "  ]}>\n",
      "  <TabItem value=\"cli\">\n",
      "\n",
      "Desp√∫es, inicia sesi√≥n en W&B:\n",
      "\n",
      "```\n",
      "wandb login\n",
      "```\n",
      "\n",
      "O si est√°s usando [W&B Server:](./guides/hosting)\n",
      "\n",
      "```\n",
      "wandb login --host=http://wandb.tu-servidor-compartido.local\n",
      "```\n",
      "\n",
      "Proporciona [tu clave API](https://wandb.ai/authorize) cuando te lo soliciten.\n",
      "\n",
      "  </TabItem>\n",
      "  <TabItem value=\"notebook\">\n",
      "\n",
      "Desp√∫es, importa la SDK de Python de W&B y inicia sesi√≥n:\n",
      "\n",
      "```python\n",
      "wandb.login()\n",
      "```\n",
      "\n",
      "Proporciona [tu clave API](https://wandb.ai/authorize) cuando te lo soliciten.\n",
      "  </TabItem>\n",
      "</Tabs>\n",
      "\n",
      "## 3. Inicia un run y rastrea hiperpar√°metros\n",
      "\n",
      "Inicializa un objeto de run de W&B en tu script o notebook de Python con [`wandb.init()`](./ref/python/run.md) y pasa un diccionario al par√°metro `config` con pares clave-valor de nombres de hiperpar√°metros y valores:\n",
      "\n",
      "```python\n",
      "run = wandb.init(\n",
      "    # Establece el proyecto en el que se registrar√° este run\n",
      "    project=\"mi-proyecto-genial\",\n",
      "    # Rastrea hiperpar√°metros y metadatos de runs\n",
      "    config={\n",
      "        \"tasa_aprendizaje\": 0.01,\n",
      "        \"epocas\": 10,\n",
      "    })\n",
      "```\n",
      "\n",
      "<!-- ```python\n",
      "run = wandb.init(project=\"mi-proyecto-genial\")\n",
      "``` -->\n",
      "\n",
      "Un [run](./guides/runs) es la unidad b√°sica de W&B. Usar√°s muchos de ellos para [rastrear m√©tricas](./guides/track), [crear registros](./guides/artifacts), [crear trabajos](./guides/launch), y m√°s.\n",
      "\n",
      "\n",
      "<!-- ## Rastrear m√©tricas -->\n",
      "<!-- Pasa un diccionario al par√°metro `config` con pares clave-valor de nombre de hiperpar√°metro y valores cuando inicializas un objeto de run:\n",
      "\n",
      "```python\n",
      "  # Rastrea hiperpar√°metros y metadatos de runs\n",
      "  config={\n",
      "      \"tasa_aprendizaje\": lr,\n",
      "      \"epocas\": epochs,\n",
      "  }\n",
      "``` -->\n",
      "\n",
      "\n",
      "<!-- Utiliza [`wandb.log()`](./ref/python/log.md) para rastrear m√©tricas:\n",
      "\n",
      "```python\n",
      "wandb.log({'precisi√≥n': precisi√≥n, 'p√©rdida': p√©rdida})\n",
      "```\n",
      "\n",
      "Cualquier cosa que rastrees con `wandb.log` se almacena en el objeto de run m√°s reciente que se inicializ√≥. -->\n",
      "\n",
      "## Pasos siguientes\n",
      "\n",
      "Explora el resto del ecosistema de W&B.\n",
      "\n",
      "1. Revisa [Integraciones de W&B](guides/integrations) para aprender a integrar W&B con tu marco de aprendizaje de m√°quina como PyTorch, tu biblioteca de aprendizaje de m√°quina como Hugging Face, o tu servicio de aprendizaje de m√°quina como SageMaker. \n",
      "2. Organiza tus runs, crea y automatiza visualizaciones, describe tus hallazgos, y comparte actualizaciones con colaboradores con [W&B Reportes](./guides/reports).\n",
      "3. Crea [Artifactos de W&B](./guides/artifacts) para rastrear conjuntos de datos, modelos, dependencias, y resultados a lo largo de tu pipeline de aprendizaje de m√°quina.\n",
      "4. Busca la mejor combinaci√≥n de hiperpar√°metros y explora el espacio de posibles modelos con [W&B Sweeps](./guides/sweeps).\n",
      "5. Entiende tus conjuntos de datos, visualiza predicciones de modelos, y comparte insight en un [panel de control central](./guides/data-vis).\n",
      "\n",
      "\n",
      "![](/images/quickstart/wandb_demo_experiments.gif) \n",
      "\n",
      "## Preguntas comunes\n",
      "\n",
      "**D√≥nde encuentro mi clave API?**\n",
      "Despu√©s de haber iniciado sesi√≥n en [www.wandb.ai](https://wandb.ai), encontrar√°s tu clave API en la p√°gina [Autorizar](https://wandb.ai/authorize).\n",
      "\n",
      "**C√≥mo uso W&B en un entorno automatizado?**\n",
      "Si est√°s entrenando modelos en un entorno automatizado donde resulta inconveniente ejecutar comandos de shell, como Google's CloudML, deber√≠as revisar nuestra gu√≠a sobre configuraci√≥n con [Variables de Entorno](guides/track/environment-variables).\n",
      "\n",
      "**Ofrecemos instalaciones locales, en el propio?**\n",
      "S√≠, puedes [alojar W&B](guides/hosting/) localmente en tus propias m√°quinas o en una nube privada. Intenta este r√°pido tutorial de notebook para ver c√≥mo. Nota, para iniciar sesi√≥n en el servidor de wandb local, puedes [establecer la bandera de host](guides/hosting/how-to-guides/basic-setup) a la direcci√≥n de la instancia local.  \n",
      "\n",
      "**C√≥mo desactivo el registro de wandb temporalmente?**\n",
      "Si est√°s probando c√≥digo y quieres desactivar la sincronizaci√≥n de wandb, establece la variable de entorno [`WANDB_MODE=offline`](./guides/track/environment-variables).\n",
      "\n",
      "Stop reason: stop\n",
      "\n",
      "üç© https://wandb.ai/capecape/bedrock-weave/r/call/33e0cfa5-a206-4cec-b5db-27f93f8677d2\n",
      "Text:\n",
      " <Markdown start>\n",
      "---\n",
      "description: >-\n",
      "  Una visi√≥n general de lo que es W&B y enlaces para empezar si eres un usuario nuevo.\n",
      "slug: /guides\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "# ¬øQu√© es W&B?\n",
      "\n",
      "W&B es la plataforma de aprendizaje autom√°tico para desarrolladores para construir mejores modelos m√°s r√°pido. Use las herramientas ligeras e interoperables de W&B para r√°pidamente rastrear experimentos, versionar y iterar en conjuntos de datos, evaluar el rendimiento de modelos, reproducir modelos, visualizar resultados y detectar regresiones, y compartir hallazgos con tus colegas.\n",
      "Configure W&B en 5 minutos y luego iterar r√°pidamente en tu canal de producci√≥n de aprendizaje autom√°tico con la confianza de que tus conjuntos de datos y modelos est√°n rastreados y versionados en un sistema de registro confiable.\n",
      "\n",
      "<!-- ![](@site/static/images/general/diagram_2021.png) -->\n",
      "\n",
      "## ¬øEres un nuevo usuario de W&B?\n",
      "\n",
      "Si est√°s utilizando W&B por primera vez, sugieremos que explores lo siguiente:\n",
      "\n",
      "1. Experimenta W&B en acci√≥n, [ejecute un proyecto de introducci√≥n de Google Colab](http://wandb.me/intro).\n",
      "2. Lee a trav√©s de la [Gu√≠a r√°pida](../quickstart.md) para obtener una visi√≥n general de c√≥mo y d√≥nde agregar W&B a tu c√≥digo.\n",
      "3. Lee [C√≥mo funciona W&B?](#c√≥mo-funciona-weights--biases) Esta secci√≥n proporciona una visi√≥n general de los bloques de construcci√≥n de W&B.\n",
      "4. Explora nuestra [Gu√≠a de integraciones](./integrations/intro.md) y nuestra [Playlist de integraciones de Weave en YouTube](https://www.youtube.com/playlist?list=PLD80i8An1OEGDADxOBaH71ZwieZ9nmPGC) para obtener informaci√≥n sobre c√≥mo integrar W&B con tu marco de aprendizaje autom√°tico preferido.\n",
      "5. Revise la [Gu√≠a de referencia de API](../ref/README.md) para especificaciones t√©cnicas sobre la Biblioteca de Python de W&B, la CLI y las operaciones de Weave.\n",
      "\n",
      "## C√≥mo funciona W&B?\n",
      "\n",
      "Recomendamos que leas estas secciones en este orden si eres un usuario nuevo de W&B:\n",
      "\n",
      "1. Aprende sobre [Corrida](./runs/intro.md), la unidad b√°sica de computo de W&B.\n",
      "2. Cree y rastree experimentos de aprendizaje autom√°tico con [Experimentos](./track/intro.md).\n",
      "3. Descubre el bloque flexible y ligero de W&B para la versionaci√≥n de conjuntos de datos y modelos con [Artifacts](./artifacts/intro.md).\n",
      "4. Automatice la b√∫squeda de hiperpar√°metros y explore el espacio de posibles modelos con [Sweeps](./sweeps/intro.md).\n",
      "5. Administre el ciclo de vida del modelo desde el entrenamiento hasta la producci√≥n con [Gesti√≥n de modelos](./models/intro.md).\n",
      "6. Visualice predicciones a lo largo de versiones de modelos con nuestra [Gu√≠a de visualizaci√≥n de datos](./data-vis/intro.md).\n",
      "7. Organice las corridas de W&B, enmarque y automatice visualizaciones, describa tus hallazgos y compartas actualizaciones con colaboradores con [Informes](./reports/intro.md).\n",
      "\n",
      "<End of Markdown>\n",
      "\n",
      "Stop reason: stop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    output = generate_text(model_id, prompt_template.format_mistral_instruct(doc), max_tokens=2048)\n",
    "    print(f\"Text:\\n{output[0]['text']}\\n\")\n",
    "    print(f\"Stop reason: {output[0]['stop_reason']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4708c4d3-4707-42d3-b59c-1335a7f55477",
   "metadata": {},
   "source": [
    "We can improve our weave experience by creating a `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4d8f93b-a51b-47e5-a7a6-5230dce672ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from weave import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0191b0e0-f66d-4f0a-a3f5-5aa2c76dd80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MistralInstruct(Model):\n",
    "    prompt_template: PromptTemplate\n",
    "    temperature: float=0.7\n",
    "    max_tokens: int=2048\n",
    "    model_id: str='mistral.mistral-7b-instruct-v0:2'\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, document: str) -> dict:\n",
    "        output = generate_text(\n",
    "             model_id, \n",
    "             self.prompt_template.format_mistral_instruct(document), \n",
    "             temperature=self.temperature,\n",
    "             max_tokens=self.max_tokens,\n",
    "        )\n",
    "        return output[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf9ea785-c850-4780-9336-7521399e301e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MistralInstruct(prompt_template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7285ce21-6663-4293-b819-305e2ff670cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/bedrock-weave/r/call/1b4327fc-4398-46f6-9522-bffae3af0a7f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ---\\ndescription: Inicio r√°pido de W&B.\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Inicio r√°pido\\n\\nComience a rastrear sus experimentos de aprendizaje autom√°tico en W&B en minutos.\\n\\n## 1. Crea una cuenta y instala W&B\\nAntes de empezar, cree una cuenta y instale W&B:\\n\\n1. [Reg√≠strate](https://wandb.ai/site) gratis en [https://wandb.ai/site](https://wandb.ai/site) y luego inicie sesi√≥n en tu cuenta de wandb.  \\n2. Instale la biblioteca wandb en tu m√°quina en un entorno Python 3 usando [`pip`](https://pypi.org/project/wandb/).  \\n<!-- 3. Inicie sesi√≥n en la biblioteca wandb en tu m√°quina. Encuentre su clave API aqu√≠: [https://wandb.ai/authorize](https://wandb.ai/authorize).   -->\\n\\nLos siguientes fragmentos de c√≥digo muestran c√≥mo instalar y iniciar sesi√≥n en W&B usando la CLI y la biblioteca de Python:\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'L√≠nea de comandos\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nInstale la CLI y la biblioteca de Python para interactuar con la API de Weights and Biases:\\n\\n```\\npip install wandb\\n```\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nInstale la CLI y la biblioteca de Python para interactuar con la API de Weights and Biases:\\n\\n```python\\n!pip install wandb\\n```\\n\\n\\n  </TabItem>\\n</Tabs>\\n\\n## 2. Inicia sesi√≥n en W&B\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'L√≠nea de comandos\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nDespu√©s, inicia sesi√≥n en W&B:\\n\\n```\\nwandb login\\n```\\n\\nO si est√° usando [W&B Server:](./guides/hosting)\\n\\n```\\nwandb login --host=http://wandb.tu-servidor-compartido.local\\n```\\n\\nProporcione [su clave API](https://wandb.ai/authorize) cuando se solicite.\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nDespu√©s, importe la SDK de Python de W&B y inicie sesi√≥n:\\n\\n```python\\nwandb.login()\\n```\\n\\nProporcione [su clave API](https://wandb.ai/authorize) cuando se solicite.\\n  </TabItem>\\n</Tabs>\\n\\n## 3. Inicia un run y rastrea hiperpar√°metros\\n\\nInicie un objeto de corrida de W&B en su script o notebook de Python con [`wandb.init()`](./ref/python/run.md) y pase un diccionario al par√°metro `config` con pares clave-valor de nombres de hiperpar√°metros y valores:\\n\\n```python\\nrun = wandb.init(\\n    # Establezca el proyecto en el que se registrar√° esta corrida\\n    project=\"mi-proyecto-genial\",\\n    # Rastrear hiperpar√°metros y metadatos de la corrida\\n    config={\\n        \"tasa_aprendizaje\": 0.01,\\n        \"epocas\": 10,\\n    })\\n```\\n\\n\\n<!-- ```python\\nrun = wandb.init(project=\"mi-proyecto-genial\")\\n``` -->\\n\\nUn [corrida](./guides/runs) es la unidad b√°sica de W&B. Usar√° frecuentemente corrida para [rastrear m√©tricas](./guides/track), [crear registros](./guides/artifacts), [crear tareas](./guides/launch), y m√°s.\\n\\n\\n<!-- ## Rastrear m√©tricas -->\\n<!-- Pasa un diccionario al par√°metro `config` con pares clave-valor de nombre de hiperpar√°metro y valores cuando inicie un objeto de corrida:\\n\\n```python\\n  # Rastrear hiperpar√°metros y metadatos de la corrida\\n  config={\\n      \"tasa_aprendizaje\": lr,\\n      \"epocas\": epochs,\\n  }\\n``` -->\\n\\n\\n<!-- Use [`wandb.log()`](./ref/python/log.md) para rastrear m√©tricas:\\n\\n```python\\nwandb.log({\\'precisi√≥n\\': precisi√≥n, \\'p√©rdida\\': p√©rdida})\\n```\\n\\nCualquier cosa que registre con `wandb.log` se almacena en el objeto de corrida que se inici√≥ recientemente. -->\\n\\n## Pasos siguientes\\n\\nExplore el resto del ecosistema de W&B.\\n\\n1. Consulte [Integraciones de W&B](guides/integrations) para aprender a integrar W&B con su framework de aprendizaje autom√°tico como PyTorch, su biblioteca de machine learning como Hugging Face, o su servicio de machine learning como SageMaker. \\n2. Organice corrida, embed y automatice visualizaciones, describa sus hallazgos, y comparte actualizaciones con colaboradores con [W&B Informes](./guides/reports).\\n3. Cree [Artifactos de W&B](./guides/artifacts) para rastrear conjuntos de datos, modelos, dependencias, y resultados a lo largo de su pipeline de machine learning.\\n4. Realice b√∫squeda de hiperpar√°metros automatizada y explore el espacio de posibles modelos con [W&B Sweeps](./guides/sweeps).\\n5. Entenda sus conjuntos de datos, visualice predicciones de modelos, y comparte insight en un [panel de control central](./guides/data-vis).\\n\\n\\n![Muestra las p√©rdidas y precisiones que se rastrearon cada vez que se ejecut√≥ el script anterior. ](/images/quickstart/quickstart_image.png)\\n\\n\\n\\n## Preguntas comunes\\n\\n**¬øD√≥nde encuentro mi clave API?**\\nDespu√©s de haber iniciado sesi√≥n en [www.wandb.ai](https://wandb.ai), encontrar√° su clave API en la p√°gina [Autorizar](https://wandb.ai/authorize).\\n\\n**¬øC√≥mo uso W&B en un entorno automatizado?**\\nSi est√° entrenando modelos en un entorno automatizado donde resulta inconveniente ejecutar comandos de shell, como Google\\'s CloudML, debe revisar nuestra gu√≠a de configuraci√≥n con [Variables de Entorno](guides/track/environment-variables).\\n\\n**¬øOfrecemos instalaciones locales, en la nube privada?**\\nS√≠, puede [alojar W&B localmente](guides/hosting/) en sus propias m√°quinas o en una nube privada, int√©ntese con este r√°pido tutorial de notebook para ver c√≥mo. Nota, para iniciar sesi√≥n en el servidor W&B local, puede [establecer la bandera host](guides/hosting/how-to-guides/basic-setup) a la direcci√≥n de la instancia local.  \\n\\n**¬øC√≥mo desactivo el registro de wandb temporalmente?**\\nSi est√° probando c√≥digo y desea desactivar la sincronizaci√≥n de wandb, establezca la variable de entorno [`WANDB_MODE=offline`](./guides/track/environment-variables).'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f3ade-72c9-46a5-ad0a-9a88f08a8c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
